{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tjNfgZDNOdrw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision.datasets import VOCDetection, Caltech256\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torcheval.metrics.functional import multiclass_f1_score, multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f805be7f230>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MK_LduJSOh7s"
   },
   "outputs": [],
   "source": [
    "def get_center_updated(target):\n",
    "    image_width= int(target['annotation']['size']['width'])\n",
    "    image_height= int(target['annotation']['size']['height'])\n",
    "    max_area_class = ''\n",
    "    max_area = 0\n",
    "    max_area_coordinates = None\n",
    "\n",
    "\n",
    "# Find the object with the largest bounding box area\n",
    "    for i in range(len(target['annotation']['object'])):\n",
    "        coord = target['annotation']['object'][i]['bndbox']\n",
    "        area = (int(coord['xmax']) - int(coord['xmin'])) * (int(coord['ymax']) - int(coord['ymin']))\n",
    "\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_area_class = target['annotation']['object'][i]['name']\n",
    "            max_area_coordinates = coord\n",
    "\n",
    "    if max_area_coordinates is not None:\n",
    "        # Calculate the size of the square (maximum of width and height of the bounding box)\n",
    "        square_size = max(int(max_area_coordinates['xmax']) - int(max_area_coordinates['xmin']),\n",
    "                          int(max_area_coordinates['ymax']) - int(max_area_coordinates['ymin']))\n",
    "\n",
    "        # Calculate the coordinates for the square centered on the bounding box\n",
    "        center_x = (int(max_area_coordinates['xmin']) + int(max_area_coordinates['xmax'])) // 2\n",
    "        center_y = (int(max_area_coordinates['ymin']) + int(max_area_coordinates['ymax'])) // 2\n",
    "        half_size = square_size // 2\n",
    "        new_xmin = max(0, center_x - half_size)\n",
    "        new_xmax = min(image_width, center_x + half_size)\n",
    "        new_ymin = max(0, center_y - half_size)\n",
    "        new_ymax = min(image_height, center_y + half_size)\n",
    "\n",
    "        # Return the coordinates of the largest square including the bounding box\n",
    "        square_coordinates = {\n",
    "            'xmin': str(new_xmin),\n",
    "            'ymin': str(new_ymin),\n",
    "            'xmax': str(new_xmax),\n",
    "            'ymax': str(new_ymax)\n",
    "        }\n",
    "        return square_coordinates, max_area_class\n",
    "\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedCaltech256Dataset(Caltech256):\n",
    "    def __init__(self, path='./data', download_flag=False, validation_flag=False):\n",
    "        super(ModifiedCaltech256Dataset, self).__init__(path, None, None, download_flag)\n",
    "        self.classes = []\n",
    "        self.labels = []\n",
    "        # self.means = torch.zeros((3, 1), dtype=torch.float32)\n",
    "        # self.vars = torch.zeros((3, 1), dtype=torch.float32)\n",
    "        self.means = torch.from_numpy(np.array([[0.5520],\n",
    "                                    [0.5336],\n",
    "                                    [0.5050]], dtype=np.float32))\n",
    "        self.means = torch.from_numpy(np.array([[0.1973],\n",
    "                                    [0.1930],\n",
    "                                    [0.2098]], dtype=np.float32))\n",
    "        if validation_flag:\n",
    "            self.transform_mod = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                # transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "                # transforms.RandomHorizontalFlip(),\n",
    "                # transforms.RandomRotation((-45., +45.)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform_mod = transforms.Compose([\n",
    "                # transforms.Resize((256, 256)),\n",
    "                transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation((0., 45.)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(ModifiedCaltech256Dataset, self).__getitem__(index)\n",
    "        img_tensor = self.transform_mod(img)\n",
    "        if img_tensor.dim()==2:\n",
    "            img_tensor = img_tensor[None, ...].expand(3, -1, -1)\n",
    "        elif img_tensor.shape[0]==1:\n",
    "            img_tensor = img_tensor.expand(3, -1, -1)\n",
    "        self.labels.append(target)\n",
    "        img_tensor = transforms.Normalize(mean=[0.5520, 0.5336, 0.5050], std=[0.1973, 0.1930, 0.2098])(img_tensor)\n",
    "        # self.means += torch.mean(img_tensor.reshape(3, -1), dim=1, keepdim=True)/super(ModifiedCaltech256Dataset, self).__len__()\n",
    "        # self.vars += torch.pow(torch.mean(img_tensor.reshape(3, -1), dim=1, keepdim=True)-self.means, 2)/super(ModifiedCaltech256Dataset, self).__len__()\n",
    "        return img_tensor, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "180Y7OarOh5t"
   },
   "outputs": [],
   "source": [
    "class ModifiedCaltech256Dataset(Caltech256):\n",
    "    def __init__(self, path='./data', download_flag=False, validation_flag=False):\n",
    "        super(ModifiedCaltech256Dataset, self).__init__(path, None, None, download_flag)\n",
    "        self.classes = []\n",
    "        self.labels = []\n",
    "        # self.means = torch.zeros((3, 1), dtype=torch.float32)\n",
    "        # self.vars = torch.zeros((3, 1), dtype=torch.float32)\n",
    "        self.means = torch.from_numpy(np.array([[0.5520],\n",
    "                                    [0.5336],\n",
    "                                    [0.5050]], dtype=np.float32))\n",
    "        self.means = torch.from_numpy(np.array([[0.1973],\n",
    "                                    [0.1930],\n",
    "                                    [0.2098]], dtype=np.float32))\n",
    "        if validation_flag:\n",
    "            self.transform_mod = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                # transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "                # transforms.RandomHorizontalFlip(),\n",
    "                # transforms.RandomRotation((-45., +45.)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform_mod = transforms.Compose([\n",
    "                # transforms.Resize((256, 256)),\n",
    "                transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                # transforms.RandomRotation((-45., +45.)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(ModifiedCaltech256Dataset, self).__getitem__(index)\n",
    "        img_tensor = self.transform_mod(img)\n",
    "        if img_tensor.dim()==2:\n",
    "            img_tensor = img_tensor[None, ...].expand(3, -1, -1)\n",
    "        elif img_tensor.shape[0]==1:\n",
    "            img_tensor = img_tensor.expand(3, -1, -1)\n",
    "        self.labels.append(target)\n",
    "        img_tensor = transforms.Normalize(mean=[0.5520, 0.5336, 0.5050], std=[0.1973, 0.1930, 0.2098])(img_tensor)\n",
    "        # self.means += torch.mean(img_tensor.reshape(3, -1), dim=1, keepdim=True)/super(ModifiedCaltech256Dataset, self).__len__()\n",
    "        # self.vars += torch.pow(torch.mean(img_tensor.reshape(3, -1), dim=1, keepdim=True)-self.means, 2)/super(ModifiedCaltech256Dataset, self).__len__()\n",
    "        return img_tensor, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Pc-ekrMaOh2r"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7mstLztOh0F",
    "outputId": "dd4bb739-8205-479d-d387-ca923fcbade3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download and prepare the dataset\n",
    "dataset = ModifiedCaltech256Dataset('./data', True)\n",
    "# dataset = ModifiedVOCDataset(root='./data', year='2012', image_set='trainval', download=True)\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=False, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KJwD40rF9zGh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ragraw06/UBCO/rishabh/AI_conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ragraw06/UBCO/rishabh/AI_conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model setup\n",
    "model = resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 257)  # 20 classes in Pascal VOC\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for param in model.fc.parameters():\n",
    "    if param.requires_grad and param.dim()>1:\n",
    "        nn.init.xavier_normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, lr_scheduler, epoch, model_path):\n",
    "    try:\n",
    "        torch.save({'epoch':epoch,\n",
    "                    # 'config':vars(config),\n",
    "                    'state_dict':model.state_dict(),\n",
    "                    'optimizer':optimizer.state_dict(),\n",
    "                    'scheduler':lr_scheduler.state_dict()}, model_path)\n",
    "    except Exception as err:\n",
    "        print(f\"Unexpected {err=}, {type(err)=}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def load_model(model, optimizer, lr_scheduler, model_path):\n",
    "    check_point = torch.load(model_path)\n",
    "    epoch = check_point['epoch']\n",
    "    # print(check_point['config'])\n",
    "    config = Namespace(**check_point['config'])\n",
    "    model.load_state_dict(check_point['state_dict'])\n",
    "    optimizer.load_state_dict(check_point['optimizer'])\n",
    "    lr_scheduler.load_state_dict(check_point['scheduler'])\n",
    "    return model, optimizer, lr_scheduler, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [00:28<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24485,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_labels = []\n",
    "for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "    all_labels.append(labels)\n",
    "all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "print(all_labels.shape)\n",
    "uniques, counts = np.unique(all_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(all_labels, bins=np.arange(len(uniques)+1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2060, 1.1762, 0.7939, 0.9924, 0.8583, 1.4220, 1.0826, 0.5068, 1.1479,\n",
      "        1.3610, 0.4272, 0.5293, 1.1078, 1.3419, 0.9722, 1.2703, 1.1762, 1.1209,\n",
      "        0.9722, 1.3610, 0.8822, 1.3419, 1.1078, 1.0244, 1.0135, 1.1342, 1.2214,\n",
      "        1.0244, 1.2214, 1.1479, 1.2536, 1.1078, 1.1479, 1.2214, 1.4886, 1.1479,\n",
      "        0.9822, 1.1479, 1.4657, 0.8741, 1.5367, 1.2536, 0.9722, 0.9822, 1.3419,\n",
      "        0.9433, 1.3232, 1.2214, 0.9822, 1.1479, 1.0826, 1.3808, 1.4435, 1.0356,\n",
      "        1.2373, 1.1909, 1.1078, 1.2536, 1.3419, 1.4011, 1.2373, 1.3610, 1.0135,\n",
      "        0.8822, 1.1619, 1.3610, 1.4011, 1.0469, 1.0951, 1.3419, 1.2214, 1.0586,\n",
      "        1.2703, 1.0586, 1.5123, 1.3808, 1.4220, 1.4220, 1.2060, 1.0244, 1.1619,\n",
      "        1.4657, 1.3808, 1.4220, 1.0826, 1.5367, 1.2060, 1.1619, 1.0951, 0.5571,\n",
      "        1.2214, 0.5992, 1.0826, 1.2060, 1.2875, 0.4054, 1.3419, 1.1619, 1.4011,\n",
      "        1.2536, 0.8661, 1.4435, 0.9924, 1.2373, 0.4390, 1.3610, 1.5879, 1.3808,\n",
      "        0.7939, 1.3232, 1.4220, 1.4886, 1.0135, 0.9527, 1.2703, 1.1078, 0.9623,\n",
      "        1.0356, 1.2875, 0.8741, 1.3808, 1.1479, 1.0586, 1.2703, 1.2536, 0.4962,\n",
      "        0.9527, 1.1078, 0.6187, 1.2703, 1.2875, 0.6616, 0.9161, 1.0135, 1.3232,\n",
      "        1.4220, 0.7683, 0.5992, 1.4657, 1.2703, 0.9722, 1.1342, 0.9161, 1.3610,\n",
      "        0.1498, 1.5123, 0.5809, 0.6757, 1.1619, 1.0135, 1.1209, 1.0135, 1.2875,\n",
      "        1.2060, 1.3232, 1.2536, 1.3232, 0.7683, 0.5881, 1.4011, 1.1619, 1.4011,\n",
      "        1.3232, 1.2703, 1.5618, 1.2875, 1.3051, 0.8506, 1.2373, 1.1078, 1.5618,\n",
      "        1.2214, 1.1078, 1.4435, 1.4657, 1.0826, 1.2373, 1.4657, 1.4657, 1.2373,\n",
      "        1.2536, 1.0469, 1.1762, 1.3808, 1.1342, 1.5123, 1.4011, 1.2536, 0.9623,\n",
      "        1.0356, 1.0469, 1.0135, 0.6662, 1.0951, 1.3232, 1.0705, 1.2060, 1.1209,\n",
      "        1.0951, 1.1762, 1.5123, 1.3051, 1.3051, 1.4886, 1.4886, 1.1479, 0.9924,\n",
      "        1.1479, 1.1342, 1.0826, 1.2060, 0.9250, 1.2060, 0.8583, 1.4657, 1.3232,\n",
      "        1.2060, 1.5123, 1.4886, 1.2875, 1.0951, 1.3051, 1.5879, 1.0469, 1.3051,\n",
      "        1.1762, 0.8431, 1.2536, 1.2060, 1.3419, 1.0951, 0.3355, 1.1209, 1.0244,\n",
      "        0.9822, 1.3051, 1.3610, 1.1909, 1.3808, 0.5705, 1.2373, 1.2214, 1.3051,\n",
      "        1.2373, 1.3610, 1.1342, 1.2373, 1.3808, 1.2373, 1.2373, 0.1455, 1.0826,\n",
      "        0.2730, 1.2060, 1.1909, 1.0951, 0.1431], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "weights = np.zeros((len(uniques)), dtype=np.float32)\n",
    "uniques, counts = np.unique(all_labels, return_counts=True)\n",
    "weights[uniques] += counts\n",
    "weights = np.sum(counts)/(len(uniques)*weights)\n",
    "weights = torch.from_numpy(weights).to(device)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n",
      "3072 7680\n",
      "768 1920\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "frozen_ratio = 0.2\n",
    "warmup_frac = 0.2\n",
    "total_iterations = num_epochs * len(train_loader)\n",
    "print(total_iterations)\n",
    "print(int((1.-frozen_ratio)*0.4*total_iterations), int((1.-frozen_ratio)*total_iterations))\n",
    "print(int(frozen_ratio*0.4*total_iterations), int(frozen_ratio*total_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cP32smiROsIF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:49<00:00,  1.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [1/50], Train Accuracy: 27.24%, Validation Accuracy: 69.73% \n",
      "Loss Train: 4.400668290754159 | Val: 2.2290254334608712\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [2/50], Train Accuracy: 77.81%, Validation Accuracy: 80.41% \n",
      "Loss Train: 1.317107429727912 | Val: 0.9299683260420958\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:43<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [3/50], Train Accuracy: 85.10%, Validation Accuracy: 83.53% \n",
      "Loss Train: 0.680356893222779 | Val: 0.7306934390217066\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [4/50], Train Accuracy: 88.31%, Validation Accuracy: 84.33% \n",
      "Loss Train: 0.49696899034703773 | Val: 0.6648794791350762\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:43<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [5/50], Train Accuracy: 90.60%, Validation Accuracy: 84.51% \n",
      "Loss Train: 0.3998516508533309 | Val: 0.6458628755062819\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:43<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [6/50], Train Accuracy: 91.73%, Validation Accuracy: 85.12% \n",
      "Loss Train: 0.3379150783487906 | Val: 0.6083032203217348\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:43<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [7/50], Train Accuracy: 93.11%, Validation Accuracy: 85.95% \n",
      "Loss Train: 0.28587703437854844 | Val: 0.6008325510968765\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Accuracy: 94.34%, Validation Accuracy: 85.92% \n",
      "Loss Train: 0.25009412155486643 | Val: 0.5887940401832262\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:43<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Accuracy: 94.92%, Validation Accuracy: 85.48% \n",
      "Loss Train: 0.22617456666193902 | Val: 0.5895861455549797\n",
      "Last Layer Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Accuracy: 95.50%, Validation Accuracy: 85.90% \n",
      "Loss Train: 0.20988153495515385 | Val: 0.5833151446034511\n",
      "Full Network Tuning\n",
      "Initializing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [11/50], Train Accuracy: 95.84%, Validation Accuracy: 86.62% \n",
      "Loss Train: 0.19113917004627487 | Val: 0.5424939865867296\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [12/50], Train Accuracy: 96.56%, Validation Accuracy: 86.96% \n",
      "Loss Train: 0.15098956176855913 | Val: 0.5330716672663888\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:45<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [13/50], Train Accuracy: 97.93%, Validation Accuracy: 86.96% \n",
      "Loss Train: 0.09690862659287329 | Val: 0.536455376384159\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [14/50], Train Accuracy: 98.73%, Validation Accuracy: 87.03% \n",
      "Loss Train: 0.06103313266066834 | Val: 0.5520898414154848\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Accuracy: 99.04%, Validation Accuracy: 86.39% \n",
      "Loss Train: 0.046801844029687345 | Val: 0.6003250169257323\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Accuracy: 99.02%, Validation Accuracy: 85.88% \n",
      "Loss Train: 0.04659684009190338 | Val: 0.62798595863084\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Accuracy: 98.89%, Validation Accuracy: 85.46% \n",
      "Loss Train: 0.04687213693493201 | Val: 0.6704472017784914\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Accuracy: 98.73%, Validation Accuracy: 84.27% \n",
      "Loss Train: 0.05015391968481708 | Val: 0.7226695232093334\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:45<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Accuracy: 98.59%, Validation Accuracy: 84.38% \n",
      "Loss Train: 0.056224857146541275 | Val: 0.7163862083107233\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Accuracy: 98.71%, Validation Accuracy: 84.10% \n",
      "Loss Train: 0.049369096057489514 | Val: 0.7407345871130625\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Accuracy: 98.91%, Validation Accuracy: 84.58% \n",
      "Loss Train: 0.03952064055677814 | Val: 0.7341183585425218\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Accuracy: 99.22%, Validation Accuracy: 84.32% \n",
      "Loss Train: 0.032020934309305936 | Val: 0.7630056372533242\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Accuracy: 99.44%, Validation Accuracy: 84.51% \n",
      "Loss Train: 0.024036465530419566 | Val: 0.7646994187186161\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Accuracy: 99.46%, Validation Accuracy: 85.33% \n",
      "Loss Train: 0.01910903553289245 | Val: 0.7184794669349989\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Accuracy: 99.63%, Validation Accuracy: 84.56% \n",
      "Loss Train: 0.015546576636552345 | Val: 0.7592918636898199\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Accuracy: 99.77%, Validation Accuracy: 85.31% \n",
      "Loss Train: 0.011685191823441224 | Val: 0.7263511754572392\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:43<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Accuracy: 99.74%, Validation Accuracy: 85.39% \n",
      "Loss Train: 0.010041678368603849 | Val: 0.7591517238567272\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Accuracy: 99.80%, Validation Accuracy: 85.84% \n",
      "Loss Train: 0.011036934493555842 | Val: 0.7037537898868322\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Accuracy: 99.87%, Validation Accuracy: 86.16% \n",
      "Loss Train: 0.006242062662143629 | Val: 0.6988470616439978\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Accuracy: 99.91%, Validation Accuracy: 85.88% \n",
      "Loss Train: 0.00534118133418815 | Val: 0.7239408747603496\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Accuracy: 99.89%, Validation Accuracy: 86.05% \n",
      "Loss Train: 0.005585862710177025 | Val: 0.7045215635250012\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Accuracy: 99.95%, Validation Accuracy: 86.78% \n",
      "Loss Train: 0.0043710410186577064 | Val: 0.6944221071898937\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Accuracy: 99.98%, Validation Accuracy: 86.93% \n",
      "Loss Train: 0.0017366920563593642 | Val: 0.665789737055699\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Accuracy: 99.95%, Validation Accuracy: 86.67% \n",
      "Loss Train: 0.0022224890684962397 | Val: 0.6679955168316761\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [35/50], Train Accuracy: 100.00%, Validation Accuracy: 87.45% \n",
      "Loss Train: 0.0009032758860030299 | Val: 0.6377303060144186\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [36/50], Train Accuracy: 100.00%, Validation Accuracy: 87.70% \n",
      "Loss Train: 0.0005351400002003478 | Val: 0.6643336340785027\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Accuracy: 100.00%, Validation Accuracy: 87.40% \n",
      "Loss Train: 0.0004016799498079611 | Val: 0.6480091027915478\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [38/50], Train Accuracy: 100.00%, Validation Accuracy: 87.83% \n",
      "Loss Train: 0.00025574277484944713 | Val: 0.6261493979642788\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Accuracy: 100.00%, Validation Accuracy: 87.80% \n",
      "Loss Train: 0.00022421886516591863 | Val: 0.6402068318178257\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Accuracy: 100.00%, Validation Accuracy: 87.76% \n",
      "Loss Train: 0.00021138090920658215 | Val: 0.6386858659485976\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [41/50], Train Accuracy: 100.00%, Validation Accuracy: 88.01% \n",
      "Loss Train: 0.00018907343381139677 | Val: 0.643128194535772\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:43<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Accuracy: 100.00%, Validation Accuracy: 87.98% \n",
      "Loss Train: 0.00018403730306696767 | Val: 0.6394890441248814\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [43/50], Train Accuracy: 100.00%, Validation Accuracy: 88.07% \n",
      "Loss Train: 0.00014319612615546853 | Val: 0.6347477516780297\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Accuracy: 100.00%, Validation Accuracy: 87.94% \n",
      "Loss Train: 0.00019179997669501367 | Val: 0.6327292124430338\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [45/50], Train Accuracy: 100.00%, Validation Accuracy: 88.11% \n",
      "Loss Train: 0.0001514218303289757 | Val: 0.6368420055756966\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [46/50], Train Accuracy: 100.00%, Validation Accuracy: 88.11% \n",
      "Loss Train: 0.00012198099926763462 | Val: 0.6319579277187586\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Accuracy: 100.00%, Validation Accuracy: 88.06% \n",
      "Loss Train: 0.00014415664513004836 | Val: 0.6390897358457247\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model ./ft_resnet50_voc2012.pth ...\n",
      "Epoch [48/50], Train Accuracy: 100.00%, Validation Accuracy: 88.27% \n",
      "Loss Train: 0.0001192199951750202 | Val: 0.629659291356802\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Accuracy: 100.00%, Validation Accuracy: 88.06% \n",
      "Loss Train: 0.0001264189506287039 | Val: 0.6461027469485998\n",
      "Full Network Tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 192/192 [01:44<00:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Accuracy: 100.00%, Validation Accuracy: 88.09% \n",
      "Loss Train: 0.0001345602949148391 | Val: 0.629337544242541\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "# optimizer_shallowft = torch.optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "# optimizer_deepft = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer_deep = torch.optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "optimizer_frozen = torch.optim.AdamW(model.fc.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "# lr_scheduler_deep = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_deep, factor=0.5, patience=5, threshold=1e-3,\n",
    "#                                                            min_lr=1e-8, eps=1e-08, verbose=True)\n",
    "lr_scheduler_deep = get_linear_schedule_with_warmup(optimizer_deep, \n",
    "                                                    int((1.-frozen_ratio)*warmup_frac*total_iterations), \n",
    "                                                    int((1.-frozen_ratio)*total_iterations)\n",
    "                                                    # int((1.-frozen_ratio)*total_iterations)-int((1.-frozen_ratio)*warmup_frac*total_iterations)\n",
    "                                                   )\n",
    "# lr_scheduler_frozen = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_frozen, factor=0.5, patience=5, threshold=1e-2,\n",
    "#                                                            min_lr=1e-8, eps=1e-08, verbose=True)\n",
    "lr_scheduler_frozen = get_linear_schedule_with_warmup(optimizer_frozen,\n",
    "                                                      int(frozen_ratio*warmup_frac*total_iterations), \n",
    "                                                      int(frozen_ratio*total_iterations), \n",
    "                                                      # int(frozen_ratio*total_iterations)-int(frozen_ratio*warmup_frac*total_iterations)\n",
    "                                                     )\n",
    "\n",
    "# Training and Validation Loop\n",
    "deep_tune_flag = False\n",
    "optimizer = optimizer_frozen\n",
    "lr_scheduler = lr_scheduler_frozen\n",
    "val_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    if (epoch/num_epochs)<frozen_ratio:\n",
    "        print('Last Layer Tuning')\n",
    "    if (epoch/num_epochs)>=frozen_ratio:\n",
    "        print('Full Network Tuning')\n",
    "        if not deep_tune_flag:\n",
    "            print('Initializing:')\n",
    "            deep_tune_flag = True\n",
    "            optimizer = optimizer_deep\n",
    "            lr_scheduler = lr_scheduler_deep\n",
    "    \n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.cpu().item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        predicted = torch.argmax(torch.softmax(outputs.data, dim=1), dim=1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(tqdm(val_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            predicted = torch.argmax(torch.softmax(outputs.data, dim=1), dim=1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            val_loss += loss.cpu().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    train_loss /= len(train_loader)\n",
    "    # lr_scheduler.step(val_loss)\n",
    "    if val_acc<=(correct_val / total_val):\n",
    "        val_acc = correct_val / total_val\n",
    "        print('Saving Model {} ...'.format('./ft_resnet50_voc2012.pth'))\n",
    "        save_model(model, optimizer, lr_scheduler, epoch, './ft_resnet50_voc2012.pth')\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "          f\"Train Accuracy: {(correct_train / total_train) * 100:.2f}%, \"\n",
    "          f\"Validation Accuracy: {(correct_val / total_val) * 100:.2f}% \"\n",
    "          f\"\\nLoss Train: {train_loss} | Val: {val_loss}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
