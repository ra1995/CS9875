{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f26ed8-62dc-4514-9c4b-5bd291a299a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision.datasets import VOCDetection, Caltech256, CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from torcheval.metrics.functional import multiclass_f1_score, multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d901854c-5a42-4df2-a0e2-6e0598cd802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "from typing import Dict, Iterable, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba678b7-31dc-4b38-9c32-09fb511eb5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f715b88b2b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c97c4c-7378-4c0a-adbc-c06837ca6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedCIFAR10DatasetTe(CIFAR10):\n",
    "    def __init__(self, path='./data', train = False, download_flag=True, validation_flag=True):\n",
    "        super(ModifiedCIFAR10DatasetTe, self).__init__(path, train, None, None, download_flag)\n",
    "        self.classes = []\n",
    "        self.labels = []\n",
    "        # self.means = torch.zeros((3, 1), dtype=torch.float32)\n",
    "        # self.vars = torch.zeros((3, 1), dtype=torch.float32)\n",
    "        self.means = torch.from_numpy(np.array([[0.5520],\n",
    "                                    [0.5336],\n",
    "                                    [0.5050]], dtype=np.float32))\n",
    "        self.std_dev = torch.from_numpy(np.array([[0.1973],\n",
    "                                    [0.1930],\n",
    "                                    [0.2098]], dtype=np.float32))\n",
    "        self.transform_mod = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            # transforms.CenterCrop(224)\n",
    "        ])\n",
    "        self.normalize_tensor = transforms.Normalize(self.means, self.std_dev)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(ModifiedCIFAR10DatasetTe, self).__getitem__(index)\n",
    "        img_tensor = self.transform_mod(img)\n",
    "        if img_tensor.dim()==2:\n",
    "            img_tensor = img_tensor[None, ...].expand(3, -1, -1)\n",
    "        elif img_tensor.shape[0]==1:\n",
    "            img_tensor = img_tensor.expand(3, -1, -1)\n",
    "        self.labels.append(target)\n",
    "        img_tensor = transforms.Normalize(mean=[0.5520, 0.5336, 0.5050], std=[0.1973, 0.1930, 0.2098])(img_tensor)\n",
    "        return img_tensor, target, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a704b58e-4ceb-4df4-bf33-733ccf9a46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce2f8d0-2756-440e-9e7d-5c1278000fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "datasetTe = ModifiedCIFAR10DatasetTe('./data', download_flag=True)\n",
    "test_loader = DataLoader(datasetTe, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9015c7b3-5c65-447e-9995-522353f42529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD, L1FMNAttack, L2PGD\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeba9cdd-d5a9-414b-9633-f6f8011436ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [1121, 1673, 2422,  3198,  4026,  43,    4697,  5157,  5391,  6000,  6461,  7094, 7752,  8516,  8873,  9308,\n",
    "1150,  1732,  2650,  3331,  403,   4496,  4741,  5187,  5531,  6025,  6624,  7272,  8010,  8640,  9020,  95,\n",
    "1166,  1907,  2831,  3374,  4066,  4497,  4933,  519,   5670,  6034,  6818,  7446,  819,   8661,  9083,  9618,\n",
    "1221,  2088,  2868,  3400,  4167,  4544,  4952,  5233,  5685,  6329,  6837,  7566,  8237,  8663,  914,   9907,\n",
    "1605,  2189,  2889,  3541,  4359,  4593,  5112,  5351,  5905,  6394,  6888,  7633,  8391,  8671,  9159,  9926,\n",
    "1625,  2346,  3093,  3754,  4362,  4686,  5153,  5384,  5931,  6406,  703,   7644,  8451,  8708,  9219,  9980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc23e1d-7e74-4e11-bb1d-e5b6867ad99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "datasetTe = torch.utils.data.Subset(datasetTe, indices)\n",
    "attack_dl = DataLoader(datasetTe, batch_size=32, shuffle=False)\n",
    "print(len(attack_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27c9702-92db-4036-ad09-9ed3e79223de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_img(inp, shift=False, normalize=False, scale:tuple=None):\n",
    "    img = inp.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "    if scale is not None:\n",
    "        img[..., 0] = img[..., 0]*scale[1][0]\n",
    "        img[..., 1] = img[..., 1]*scale[1][1]\n",
    "        img[..., 2] = img[..., 2]*scale[1][2]\n",
    "        img[..., 0] = img[..., 0]+scale[0][0]\n",
    "        img[..., 1] = img[..., 1]+scale[0][1]\n",
    "        img[..., 2] = img[..., 2]+scale[0][2]\n",
    "    if shift:\n",
    "        img[..., 0] = img[..., 0]-img[..., 0].min()\n",
    "        img[..., 1] = img[..., 1]-img[..., 1].min()\n",
    "        img[..., 2] = img[..., 2]-img[..., 2].min()\n",
    "    if normalize:\n",
    "        img[..., 0] = img[..., 0]/img[..., 0].max()\n",
    "        img[..., 1] = img[..., 1]/img[..., 1].max()\n",
    "        img[..., 2] = img[..., 2]/img[..., 2].max()\n",
    "    img = np.clip(img*255., 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def norm_tensor(img, scale):\n",
    "    img[..., 0] = img[..., 0]*scale[1][0]\n",
    "    img[..., 1] = img[..., 1]*scale[1][1]\n",
    "    img[..., 2] = img[..., 2]*scale[1][2]\n",
    "    img[..., 0] = img[..., 0]+scale[0][0]\n",
    "    img[..., 1] = img[..., 1]+scale[0][1]\n",
    "    img[..., 2] = img[..., 2]+scale[0][2]\n",
    "    return img\n",
    "\n",
    "mean=np.array([0.4913997551666284, 0.48215855929893703, 0.4465309133731618])\n",
    "std_dev=np.array([0.24703225141799082, 0.24348516474564, 0.26158783926049628])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873061d8-6bfc-4afe-a951-520928072601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ragraw06/UBCO/rishabh/AI_conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ragraw06/UBCO/rishabh/AI_conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b074dc9e624695bf0910eb5788d082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ragraw06/UBCO/rishabh/AI_conda/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchTensor(tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                       True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                       True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "                       True,  True], device='cuda:1'))\n",
      "Robust Accuracy:0.96875| Clean Accuracy:0.875\n",
      "PyTorchTensor(tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True], device='cuda:1'))\n",
      "Robust Accuracy:1.0| Clean Accuracy:0.875\n",
      "PyTorchTensor(tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True], device='cuda:1'))\n",
      "Robust Accuracy:1.0| Clean Accuracy:0.90625\n",
      "0.9895833333333334\n",
      "0.8854166666666666\n",
      "CPU times: user 1min 2s, sys: 6.3 s, total: 1min 8s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model = resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "model.load_state_dict(torch.load('./models/sc_resnet50_voc2012_40.pth', map_location='cuda:0')['state_dict'])\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "fmodel = PyTorchModel(model, bounds=(-10, 10), device=device)\n",
    "\n",
    "clean_acc_avg = 0\n",
    "numSamplesTotal = 0\n",
    "robust_acc_avg = 0\n",
    "# plt.figure(figsize=(18, 18))\n",
    "save_dir = './sc_adversary'\n",
    "if not isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "attack_dict = {}\n",
    "for batch_iter, (inputs, classes, idx) in enumerate(tqdm(attack_dl)):\n",
    "    sampless = (inputs.to(device), classes.to(device))\n",
    "    images, labels = ep.astensors(*sampless)\n",
    "    # plt.imshow(images[0].raw.cpu().permute(1, 2, 0).numpy())\n",
    "    # print(images.shape, labels.shape)\n",
    "    numSamples = int(labels.shape[0])\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    attack = L2PGD()\n",
    "    epsilons = [\n",
    "        25, # - upper bound with 25\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    # print(raw_advs[0][0].raw.shape)\n",
    "    # print(success[0].shape)\n",
    "    # rimg = tensor_to_img(raw_advs[0][0].raw, False, False, (mean, std_dev))\n",
    "    # cimg = tensor_to_img(clipped_advs[0][0].raw, False, False, (mean, std_dev))\n",
    "    # plt.imshow(rimg)\n",
    "    # plt.imshow(cimg)\n",
    "    print(success[0])\n",
    "\n",
    "    adversarial_noise = raw_advs[0].raw.cpu()-inputs.cpu()\n",
    "    # print(adversarial_noise.shape)\n",
    "    for b_id in range(inputs.shape[0]):\n",
    "        adversarial_image = tensor_to_img(raw_advs[0].raw.cpu()[b_id], False, False, (mean, std_dev))\n",
    "        adversarial_noise_image = tensor_to_img(adversarial_noise[b_id], False, False)\n",
    "        # plt.imshow(adversarial_noise_image)\n",
    "        cv2.imwrite(join(save_dir, '{}.png'.format(idx[b_id])), adversarial_image[..., ::-1])\n",
    "        cv2.imwrite(join(save_dir, '{}_noise.png'.format(idx[b_id])), adversarial_noise_image[..., ::-1])\n",
    "        attack_dict[idx[b_id].item()] = {'l2':torch.linalg.matrix_norm(torch.mean(norm_tensor(adversarial_noise[b_id],\n",
    "                                                                                             (mean, std_dev)), axis=0), ord=2).item(), \n",
    "                                  'avg':np.mean(adversarial_noise_image)}\n",
    "        # break\n",
    "    \n",
    "    robust_accuracy = np.count_nonzero(success[0])/success[0].shape[0]\n",
    "    print('Robust Accuracy:{}| Clean Accuracy:{}'.format(robust_accuracy, clean_acc))\n",
    "    clean_acc_avg += clean_acc\n",
    "    robust_acc_avg += robust_accuracy\n",
    "    # break\n",
    "clean_acc_avg /= len(attack_dl)\n",
    "robust_acc_avg /= len(attack_dl)\n",
    "print(robust_acc_avg)\n",
    "print(clean_acc_avg)\n",
    "# df = pd.DataFrame(robust_acc_avg_np)\n",
    "# df.to_csv(\"robust_accuracy_range_SC.csv\",index=False)\n",
    "with open('./sc_adversary.pkl', 'wb') as fp:\n",
    "    pkl.dump(attack_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b94d08c-ebe9-4fc6-bed1-443cf89dab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9092e2d17f4a6aa29affe88cc22ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchTensor(tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True], device='cuda:1'))\n",
      "Robust Accuracy:1.0| Clean Accuracy:0.875\n",
      "PyTorchTensor(tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True], device='cuda:1'))\n",
      "Robust Accuracy:1.0| Clean Accuracy:1.0\n",
      "PyTorchTensor(tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "                      True, True, True, True, True, True, True, True], device='cuda:1'))\n",
      "Robust Accuracy:1.0| Clean Accuracy:0.9375\n",
      "1.0\n",
      "0.9375\n",
      "CPU times: user 55.9 s, sys: 4.75 s, total: 1min\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model = resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "model.load_state_dict(torch.load('./models/ft_resnet50_voc2012.pth', map_location='cuda:0')['state_dict'])\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "fmodel = PyTorchModel(model, bounds=(-10, 10), device=device)\n",
    "\n",
    "clean_acc_avg = 0\n",
    "numSamplesTotal = 0\n",
    "robust_acc_avg = 0\n",
    "# plt.figure(figsize=(18, 18))\n",
    "save_dir = './ft_adversary'\n",
    "if not isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "attack_dict = {}\n",
    "for batch_iter, (inputs, classes, idx) in enumerate(tqdm(attack_dl)):\n",
    "    sampless = (inputs.to(device), classes.to(device))\n",
    "    images, labels = ep.astensors(*sampless)\n",
    "    # plt.imshow(images[0].raw.cpu().permute(1, 2, 0).numpy())\n",
    "    # print(images.shape, labels.shape)\n",
    "    numSamples = int(labels.shape[0])\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    attack = L2PGD()\n",
    "    epsilons = [\n",
    "        25, # - upper bound with 25\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    # print(raw_advs[0][0].raw.shape)\n",
    "    # print(success[0].shape)\n",
    "    # rimg = tensor_to_img(raw_advs[0][0].raw, False, False, (mean, std_dev))\n",
    "    # cimg = tensor_to_img(clipped_advs[0][0].raw, False, False, (mean, std_dev))\n",
    "    # plt.imshow(rimg)\n",
    "    # plt.imshow(cimg)\n",
    "    print(success[0])\n",
    "\n",
    "    adversarial_noise = raw_advs[0].raw.cpu()-inputs.cpu()\n",
    "    for b_id in range(inputs.shape[0]):\n",
    "        adversarial_image = tensor_to_img(raw_advs[0].raw.cpu()[b_id], False, False, (mean, std_dev))\n",
    "        adversarial_noise_image = tensor_to_img(adversarial_noise[b_id], False, False)\n",
    "        # plt.imshow(adversarial_noise_image)\n",
    "        cv2.imwrite(join(save_dir, '{}.png'.format(idx[b_id])), adversarial_image[..., ::-1])\n",
    "        cv2.imwrite(join(save_dir, '{}_noise.png'.format(idx[b_id])), adversarial_noise_image[..., ::-1])\n",
    "        attack_dict[idx[b_id].item()] = {'l2':torch.linalg.matrix_norm(torch.mean(norm_tensor(adversarial_noise[b_id],\n",
    "                                                                                             (mean, std_dev)), axis=0), ord=2).item(), \n",
    "                                  'avg':np.mean(adversarial_noise_image)}\n",
    "        # break\n",
    "    \n",
    "    robust_accuracy = np.count_nonzero(success[0])/success[0].shape[0]\n",
    "    print('Robust Accuracy:{}| Clean Accuracy:{}'.format(robust_accuracy, clean_acc))\n",
    "    clean_acc_avg += clean_acc\n",
    "    robust_acc_avg += robust_accuracy\n",
    "    # break\n",
    "clean_acc_avg /= len(attack_dl)\n",
    "robust_acc_avg /= len(attack_dl)\n",
    "print(robust_acc_avg)\n",
    "print(clean_acc_avg)\n",
    "# df = pd.DataFrame(robust_acc_avg_np)\n",
    "# df.to_csv(\"robust_accuracy_range_FT.csv\",index=False)\n",
    "with open('./ft_adversary.pkl', 'wb') as fp:\n",
    "    pkl.dump(attack_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece27dc6-1143-43a2-bb05-08322bed1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model: nn.Module, layers: Iterable[str]):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.layers = layers\n",
    "        self._features = {layer: torch.empty(0) for layer in layers}\n",
    "\n",
    "        for layer_id in layers:\n",
    "            layer = dict([*self.model.named_modules()])[layer_id]\n",
    "            layer.register_forward_hook(self.save_outputs_hook(layer_id))\n",
    "\n",
    "    def save_outputs_hook(self, layer_id: str) -> Callable:\n",
    "        def fn(_, input, output):\n",
    "            self._features[layer_id] = output\n",
    "        return fn\n",
    "\n",
    "    def clear_features(self):\n",
    "        self._features = {layer: torch.empty(0) for layer in layers}\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        _ = self.model(x)\n",
    "        return self._features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26df7d6-66b9-4a75-b000-cb5bbf036ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.0.conv3', 'layer1.1.conv1', 'layer1.1.conv2', 'layer1.1.conv3', 'layer1.2.conv1', 'layer1.2.conv2', 'layer1.2.conv3', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.0.conv3', 'layer2.1.conv1', 'layer2.1.conv2', 'layer2.1.conv3', 'layer2.2.conv1', 'layer2.2.conv2', 'layer2.2.conv3', 'layer2.3.conv1', 'layer2.3.conv2', 'layer2.3.conv3', 'layer3.0.conv1', 'layer3.0.conv2', 'layer3.0.conv3', 'layer3.1.conv1', 'layer3.1.conv2', 'layer3.1.conv3', 'layer3.2.conv1', 'layer3.2.conv2', 'layer3.2.conv3', 'layer3.3.conv1', 'layer3.3.conv2', 'layer3.3.conv3', 'layer3.4.conv1', 'layer3.4.conv2', 'layer3.4.conv3', 'layer3.5.conv1', 'layer3.5.conv2', 'layer3.5.conv3', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.conv3', 'layer4.1.conv1', 'layer4.1.conv2', 'layer4.1.conv3', 'layer4.2.conv1', 'layer4.2.conv2', 'layer4.2.conv3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureExtractor(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "model.load_state_dict(torch.load('./models/sc_resnet50_voc2012_40.pth', map_location='cuda:0')['state_dict'])\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "fmodel = PyTorchModel(model, bounds=(-10, 10), device=device)\n",
    "\n",
    "conv_layers = []\n",
    "for name, layer in model.named_modules():\n",
    "    if 'conv' in name and isinstance(layer, nn.Conv2d):\n",
    "        conv_layers.append(name)\n",
    "print(conv_layers)\n",
    "\n",
    "extractor = FeatureExtractor(model, conv_layers)\n",
    "extractor.eval()\n",
    "extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485b1719-effd-429c-99b4-b2724a1c442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2b3dd0c57e43b9bd231defad612c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece3fe6ecc1c45238d9a332d344d4f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d089be7a6a4bebbf9d3e732a5ed406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f09813850418485aa5511c8652c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = './sc_adversary_features'\n",
    "if not isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "attack_dict = {}\n",
    "images_original_dir = join(save_dir, 'original')\n",
    "images_attack_dir = join(save_dir, 'adversary')\n",
    "if not isdir(images_original_dir):\n",
    "    os.mkdir(images_original_dir)\n",
    "if not isdir(images_attack_dir):\n",
    "    os.mkdir(images_attack_dir)\n",
    "    \n",
    "for batch_iter, (inputs, classes, idx) in enumerate(tqdm(attack_dl)):\n",
    "    sampless = (inputs.to(device), classes.to(device))\n",
    "    images, labels = ep.astensors(*sampless)\n",
    "    # plt.imshow(images[0].raw.cpu().permute(1, 2, 0).numpy())\n",
    "    # print(images.shape, labels.shape)\n",
    "    numSamples = int(labels.shape[0])\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    attack = L2PGD()\n",
    "    epsilons = [\n",
    "        25, # - upper bound with 25\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        o_input = inputs.to(device)\n",
    "        # for b_i in range(o_input.shape[0]):\n",
    "        #     plt.imshow(tensor_to_img(o_input[b_i].cpu(), False, False, scale=(mean, std_dev)))\n",
    "        #     plt.show()\n",
    "        #     cv2.imwrite(join(images_original_dir, 'src', '{}.png'.format(data_dict['idx'][b_i])), \n",
    "        #                 tensor_to_img(o_input[b_i].cpu(), False, False, scale=(mean, std_dev))[..., ::-1])\n",
    "        o_output = extractor(o_input).copy()\n",
    "        \n",
    "        p_input = raw_advs[0].raw.to(device)\n",
    "        for b_i in range(p_input.shape[0]):\n",
    "            attack_dict[idx[b_i].item()] = {}\n",
    "        #     plt.imshow(tensor_to_img(p_input[b_i].cpu(), False, False, scale=(mean, std_dev)))\n",
    "        #     plt.show()\n",
    "        #     cv2.imwrite(join(images_attack_dir, 'src', '{}.png'.format(data_dict['idx'][b_i])), \n",
    "        #                 tensor_to_img(p_input[b_i].cpu(), False, False, scale=(mean, std_dev))[..., ::-1])\n",
    "        p_output = extractor(p_input).copy()\n",
    "        # # print([(k,o_output[k].shape) for k in o_output.keys()])\n",
    "        # # print([(k,p_output[k].shape) for k in p_output.keys()])\n",
    "        \n",
    "        for k in tqdm(p_output.keys()):\n",
    "            # print(p_output[k].shape)\n",
    "            if not isdir(join(images_original_dir, k)):\n",
    "                os.mkdir(join(images_original_dir, k))\n",
    "            if not isdir(join(images_attack_dir, k)):\n",
    "                os.mkdir(join(images_attack_dir, k))\n",
    "                \n",
    "            for b_i in range(p_output[k].shape[0]):\n",
    "                with open(join(images_original_dir, k, '{}.pkl'.format(idx[b_i])), 'wb') as fp:\n",
    "                    pkl.dump(o_output[k][b_i].detach().cpu().numpy(), fp)            \n",
    "                with open(join(images_attack_dir, k, '{}.pkl'.format(idx[b_i])), 'wb') as fp:\n",
    "                    pkl.dump(p_output[k][b_i].detach().cpu().numpy(), fp)\n",
    "                \n",
    "                diff_norm = torch.linalg.matrix_norm(p_output[k][b_i]-o_output[k][b_i], ord=2)\n",
    "                attack_dict[idx[b_i].item()][k]=np.sqrt(diff_norm.cpu().numpy())\n",
    "        # break\n",
    "with open('./sc_adversary_features.pkl', 'wb') as fp:\n",
    "    pkl.dump(attack_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c86a2a0c-fcc7-402a-be34-f188855c6b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.0.conv3', 'layer1.1.conv1', 'layer1.1.conv2', 'layer1.1.conv3', 'layer1.2.conv1', 'layer1.2.conv2', 'layer1.2.conv3', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.0.conv3', 'layer2.1.conv1', 'layer2.1.conv2', 'layer2.1.conv3', 'layer2.2.conv1', 'layer2.2.conv2', 'layer2.2.conv3', 'layer2.3.conv1', 'layer2.3.conv2', 'layer2.3.conv3', 'layer3.0.conv1', 'layer3.0.conv2', 'layer3.0.conv3', 'layer3.1.conv1', 'layer3.1.conv2', 'layer3.1.conv3', 'layer3.2.conv1', 'layer3.2.conv2', 'layer3.2.conv3', 'layer3.3.conv1', 'layer3.3.conv2', 'layer3.3.conv3', 'layer3.4.conv1', 'layer3.4.conv2', 'layer3.4.conv3', 'layer3.5.conv1', 'layer3.5.conv2', 'layer3.5.conv3', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.conv3', 'layer4.1.conv1', 'layer4.1.conv2', 'layer4.1.conv3', 'layer4.2.conv1', 'layer4.2.conv2', 'layer4.2.conv3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureExtractor(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "model.load_state_dict(torch.load('./models/ft_resnet50_voc2012.pth', map_location='cuda:0')['state_dict'])\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "fmodel = PyTorchModel(model, bounds=(-10, 10), device=device)\n",
    "\n",
    "conv_layers = []\n",
    "for name, layer in model.named_modules():\n",
    "    if 'conv' in name and isinstance(layer, nn.Conv2d):\n",
    "        conv_layers.append(name)\n",
    "print(conv_layers)\n",
    "\n",
    "extractor = FeatureExtractor(model, conv_layers)\n",
    "extractor.eval()\n",
    "extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4d74f8f-c6d0-4661-aeef-75fde2276308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54ae83c50ad4e389ce6b5b7ba623188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680788b0325a4ed1afe883a84c2a7230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb5c2fc838c4fa2b0fb0e74b55e6920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fb197a431f4ee4a9d290f5992be075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = './ft_adversary_features'\n",
    "if not isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "attack_dict = {}\n",
    "images_original_dir = join(save_dir, 'original')\n",
    "images_attack_dir = join(save_dir, 'adversary')\n",
    "if not isdir(images_original_dir):\n",
    "    os.mkdir(images_original_dir)\n",
    "if not isdir(images_attack_dir):\n",
    "    os.mkdir(images_attack_dir)\n",
    "    \n",
    "for batch_iter, (inputs, classes, idx) in enumerate(tqdm(attack_dl)):\n",
    "    sampless = (inputs.to(device), classes.to(device))\n",
    "    images, labels = ep.astensors(*sampless)\n",
    "    # plt.imshow(images[0].raw.cpu().permute(1, 2, 0).numpy())\n",
    "    # print(images.shape, labels.shape)\n",
    "    numSamples = int(labels.shape[0])\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    attack = L2PGD()\n",
    "    epsilons = [\n",
    "        25, # - upper bound with 25\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        o_input = inputs.to(device)\n",
    "        # for b_i in range(o_input.shape[0]):\n",
    "        #     plt.imshow(tensor_to_img(o_input[b_i].cpu(), False, False, scale=(mean, std_dev)))\n",
    "        #     plt.show()\n",
    "        #     cv2.imwrite(join(images_original_dir, 'src', '{}.png'.format(data_dict['idx'][b_i])), \n",
    "        #                 tensor_to_img(o_input[b_i].cpu(), False, False, scale=(mean, std_dev))[..., ::-1])\n",
    "        o_output = extractor(o_input).copy()\n",
    "        \n",
    "        p_input = raw_advs[0].raw.to(device)\n",
    "        for b_i in range(p_input.shape[0]):\n",
    "            attack_dict[idx[b_i].item()] = {}\n",
    "        #     plt.imshow(tensor_to_img(p_input[b_i].cpu(), False, False, scale=(mean, std_dev)))\n",
    "        #     plt.show()\n",
    "        #     cv2.imwrite(join(images_attack_dir, 'src', '{}.png'.format(data_dict['idx'][b_i])), \n",
    "        #                 tensor_to_img(p_input[b_i].cpu(), False, False, scale=(mean, std_dev))[..., ::-1])\n",
    "        p_output = extractor(p_input).copy()\n",
    "        # # print([(k,o_output[k].shape) for k in o_output.keys()])\n",
    "        # # print([(k,p_output[k].shape) for k in p_output.keys()])\n",
    "\n",
    "        for k in tqdm(p_output.keys()):\n",
    "            # print(p_output[k].shape)\n",
    "            if not isdir(join(images_original_dir, k)):\n",
    "                os.mkdir(join(images_original_dir, k))\n",
    "            if not isdir(join(images_attack_dir, k)):\n",
    "                os.mkdir(join(images_attack_dir, k))\n",
    "                \n",
    "            for b_i in range(p_output[k].shape[0]):\n",
    "                with open(join(images_original_dir, k, '{}.pkl'.format(idx[b_i])), 'wb') as fp:\n",
    "                    pkl.dump(o_output[k][b_i].detach().cpu().numpy(), fp)            \n",
    "                with open(join(images_attack_dir, k, '{}.pkl'.format(idx[b_i])), 'wb') as fp:\n",
    "                    pkl.dump(p_output[k][b_i].detach().cpu().numpy(), fp)\n",
    "                \n",
    "                diff_norm = torch.linalg.matrix_norm(p_output[k][b_i]-o_output[k][b_i], ord=2)\n",
    "                attack_dict[idx[b_i].item()][k]=np.sqrt(diff_norm.cpu().numpy())\n",
    "        # break\n",
    "with open('./ft_adversary_features.pkl', 'wb') as fp:\n",
    "    pkl.dump(attack_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076a8e5-f490-41ee-94f1-936639949c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
